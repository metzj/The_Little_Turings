{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from misc_helpers import *\n",
    "from plot_functions import *\n",
    "from ml_math import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm = normalize(y)\n",
    "tX_norm = normalize(tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension lifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(tx,degree):\n",
    "    D = len(tx[0,:])\n",
    "    N = len(tx[:,0])\n",
    "    new_x = np.ones((N,1)) #add bias\n",
    "    if degree>=1:\n",
    "        for i in range(1,degree+1):\n",
    "            new_x = np.append(new_x,tx**i,axis=1) \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 211)\n"
     ]
    }
   ],
   "source": [
    "#Run this box only once!!\n",
    "degree = 7\n",
    "new_train = build_poly(tX_norm,degree)\n",
    "print(np.shape(new_train))\n",
    "tX = new_train #ECRASE LES DONNEES!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(y, x, ratio, myseed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(myseed)\n",
    "    # generate random indices\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_tr]\n",
    "    x_te = x[index_te]\n",
    "    y_tr = y[index_tr]\n",
    "    y_te = y[index_te]\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.75\n",
    "x_train, x_test, y_train, y_test = split_data(y, tX, ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanmetz/Documents/EPFL/MA3/The_Little_Turings/ml_math.py:32: RuntimeWarning: overflow encountered in matmul\n",
      "  MSE_loss = 1/(2*N)*e@e\n",
      "/Users/jordanmetz/Documents/EPFL/MA3/The_Little_Turings/ml_math.py:74: RuntimeWarning: overflow encountered in matmul\n",
      "  e = y - tx@w\n",
      "/Users/jordanmetz/Documents/EPFL/MA3/The_Little_Turings/ml_math.py:74: RuntimeWarning: invalid value encountered in matmul\n",
      "  e = y - tx@w\n",
      "/Users/jordanmetz/Documents/EPFL/MA3/The_Little_Turings/ml_math.py:77: RuntimeWarning: invalid value encountered in matmul\n",
      "  gradient = -1/N*np.transpose(tx)@e\n",
      "/Users/jordanmetz/Documents/EPFL/MA3/The_Little_Turings/ml_math.py:30: RuntimeWarning: overflow encountered in matmul\n",
      "  e = y - tx @ w\n",
      "/Users/jordanmetz/Documents/EPFL/MA3/The_Little_Turings/ml_math.py:30: RuntimeWarning: invalid value encountered in matmul\n",
      "  e = y - tx @ w\n"
     ]
    }
   ],
   "source": [
    "max_iter = 100\n",
    "gamma = 1\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_GD, loss_GD = least_squares_GD(y_train, x_train, initial_w, max_iter, gamma, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 3  gamma= 1\n",
      "i= 4  gamma= 1\n"
     ]
    }
   ],
   "source": [
    "loss_test = np.array([1e7,1e6,1e5])\n",
    "losses = []\n",
    "i = 2\n",
    "N_w = len(x_train[1,:])\n",
    "w_GD2 = np.zeros(N_w)\n",
    "max_i = 10\n",
    "while ((loss_test[i-2]>loss_test[i-1] or loss_test[i-1]>loss_test[i]) )and i<=max_i:\n",
    "    max_iter = 50\n",
    "    gamma = 1\n",
    "    N_w = len(x_train[1,:])\n",
    "    w_GD2, loss_GD =least_squares_GD(y_train,x_train,w_GD2,max_iters = max_iter,gamma = gamma,verbose = False)\n",
    "    losses = np.append(losses,loss_GD)\n",
    "    loss_test = np.append(loss_test,compute_MSE(y_test,x_test,w_GD2))\n",
    "    i=i+1\n",
    "    print('i=',i,' gamma=',gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1172ecfd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASB0lEQVR4nO3df4xdZZ3H8feXtlAqtWA7uNDp2pothi4QwLELwawlCLY122pkm9Y06oZYdRfXRCWWuKLgP6xm0ZDlh7jb+CuCFaPMag0N2gaiFJhKxVLodqhor3VhrNAVofza7/4xFxynt3PPTO/c23l4v5Km55znued+n9w7nzz3nHPPjcxEkjTxHdXpAiRJrWGgS1IhDHRJKoSBLkmFMNAlqRCTO/XEs2bNyrlz53bq6SVpQtq6devvMrOrUVvHAn3u3Ln09fV16uklaUKKiF8dqs1DLpJUCANdkgphoEtSITp2DF2SxuL555+nVqtx4MCBTpcyrqZOnUp3dzdTpkyp/BgDXdKEUqvVmD59OnPnziUiOl3OuMhM9u3bR61WY968eZUf5yEXSRPKgQMHmDlzZrFhDhARzJw5c9SfQgx0SRNOyWH+krGM0UCXpEIY6JI0Ck8++STXX3/9qB+3dOlSnnzyyXGo6E8MdEkahUMF+osvvjji4zZs2MDxxx8/XmUBXuUiSaOydu1aHnnkEc4880ymTJnCcccdx0knncS2bdvYsWMH73jHO9izZw8HDhzgIx/5CGvWrAH+dLuTp556iiVLlvDmN7+Zn/70p8yePZvbbruNY4899rBrM9AlTVhX/teD7Nj7vy3d54KTX82n/+6vD9l+9dVXs337drZt28bmzZt5+9vfzvbt21++vHDdunW85jWv4ZlnnuFNb3oT73rXu5g5c+af7WPXrl3cfPPNfPnLX2bFihV85zvfYfXq1Yddu4EuSYdh4cKFf3at+LXXXst3v/tdAPbs2cOuXbsOCvR58+Zx5plnAvDGN76RRx99tCW1GOiSJqyRZtLt8qpXverl5c2bN3PHHXdw9913M23aNBYtWtTwWvJjjjnm5eVJkybxzDPPtKSWpidFI2JdRDweEdsP0R4RcW1E9EfEAxFxdksqk6Qj0PTp0/nDH/7QsG3//v2ccMIJTJs2jYcffpgtW7a0tbYqM/SvAP8OfO0Q7UuA+fV/fwPcUP9fkoozc+ZMzjvvPE477TSOPfZYXvva177ctnjxYm688UbOOOMM3vCGN3DOOee0tbbIzOadIuYC38/M0xq0fQnYnJk319d3Aosy87cj7bOnpyf9gQtJo/XQQw9x6qmndrqMtmg01ojYmpk9jfq34jr02cCeIeu1+raDRMSaiOiLiL6BgYEWPLUk6SWtCPRGNxxoOO3PzJsysycze7q6Gv4kniRpjFoR6DVgzpD1bmBvC/YrSRqFVgR6L/Ce+tUu5wD7mx0/lyS1XtOrXCLiZmARMCsiasCngSkAmXkjsAFYCvQDTwP/MF7FSpIOrWmgZ+aqJu0J/FPLKpIkjYl3W5SkURjr7XMBvvjFL/L000+3uKI/MdAlaRSO5ED3Xi6SNApDb5974YUXcuKJJ7J+/XqeffZZ3vnOd3LllVfyxz/+kRUrVlCr1XjxxRf51Kc+xWOPPcbevXs5//zzmTVrFps2bWp5bQa6pInrh2vhf37R2n3+xemw5OpDNg+9fe7GjRu59dZbuffee8lMli1bxp133snAwAAnn3wyP/jBD4DBe7zMmDGDa665hk2bNjFr1qzW1lznIRdJGqONGzeyceNGzjrrLM4++2wefvhhdu3axemnn84dd9zBJz7xCe666y5mzJjRlnqcoUuauEaYSbdDZnL55ZfzgQ984KC2rVu3smHDBi6//HIuuugirrjiinGvxxm6JI3C0Nvnvu1tb2PdunU89dRTAPzmN7/h8ccfZ+/evUybNo3Vq1fz8Y9/nJ/97GcHPXY8OEOXpFEYevvcJUuW8O53v5tzzz0XgOOOO45vfOMb9Pf3c9lll3HUUUcxZcoUbrjhBgDWrFnDkiVLOOmkk8blpGil2+eOB2+fK2ksvH3u+N4+V5J0BDDQJakQBrqkCadTh4rbaSxjNNAlTShTp05l3759RYd6ZrJv3z6mTp06qsd5lYukCaW7u5tarUbpP2M5depUuru7R/UYA13ShDJlyhTmzZvX6TKOSB5ykaRCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhKgV6RCyOiJ0R0R8Raxu0/2VEbIqI+yPigYhY2vpSJUkjaRroETEJuA5YAiwAVkXEgmHd/gVYn5lnASuB61tdqCRpZFVm6AuB/szcnZnPAbcAy4f1SeDV9eUZwN7WlShJqqJKoM8G9gxZr9W3DfUZYHVE1IANwIcb7Sgi1kREX0T0lX5zeklqtyqBHg22Df/tp1XAVzKzG1gKfD0iDtp3Zt6UmT2Z2dPV1TX6aiVJh1Ql0GvAnCHr3Rx8SOUSYD1AZt4NTAVmtaJASVI1VQL9PmB+RMyLiKMZPOnZO6zPr4ELACLiVAYD3WMqktRGTQM9M18ALgVuBx5i8GqWByPiqohYVu/2MeD9EfFz4GbgfVnyT3JL0hGo0o9EZ+YGBk92Dt12xZDlHcB5rS1NkjQaflNUkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSpEpUCPiMURsTMi+iNi7SH6rIiIHRHxYER8s7VlSpKamdysQ0RMAq4DLgRqwH0R0ZuZO4b0mQ9cDpyXmU9ExInjVbAkqbEqM/SFQH9m7s7M54BbgOXD+rwfuC4znwDIzMdbW6YkqZkqgT4b2DNkvVbfNtQpwCkR8ZOI2BIRixvtKCLWRERfRPQNDAyMrWJJUkNVAj0abMth65OB+cAiYBXwHxFx/EEPyrwpM3sys6erq2u0tUqSRlAl0GvAnCHr3cDeBn1uy8znM/OXwE4GA16S1CZVAv0+YH5EzIuIo4GVQO+wPt8DzgeIiFkMHoLZ3cpCJUkjaxromfkCcClwO/AQsD4zH4yIqyJiWb3b7cC+iNgBbAIuy8x941W0JOlgkTn8cHh79PT0ZF9fX0eeW5ImqojYmpk9jdr8pqgkFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVIhKgR4RiyNiZ0T0R8TaEfpdHBEZET2tK1GSVEXTQI+IScB1wBJgAbAqIhY06Dcd+GfgnlYXKUlqrsoMfSHQn5m7M/M54BZgeYN+nwU+BxxoYX2SpIqqBPpsYM+Q9Vp928si4ixgTmZ+f6QdRcSaiOiLiL6BgYFRFytJOrQqgR4NtuXLjRFHAV8APtZsR5l5U2b2ZGZPV1dX9SolSU1VCfQaMGfIejewd8j6dOA0YHNEPAqcA/R6YlSS2qtKoN8HzI+IeRFxNLAS6H2pMTP3Z+aszJybmXOBLcCyzOwbl4olSQ01DfTMfAG4FLgdeAhYn5kPRsRVEbFsvAuUJFUzuUqnzNwAbBi27YpD9F10+GVJkkbLb4pKUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYWoFOgRsTgidkZEf0SsbdD+0YjYEREPRMSPIuJ1rS9VkjSSpoEeEZOA64AlwAJgVUQsGNbtfqAnM88AbgU+1+pCJUkjqzJDXwj0Z+buzHwOuAVYPrRDZm7KzKfrq1uA7taWKUlqpkqgzwb2DFmv1bcdyiXADxs1RMSaiOiLiL6BgYHqVUqSmqoS6NFgWzbsGLEa6AE+36g9M2/KzJ7M7Onq6qpepSSpqckV+tSAOUPWu4G9wztFxFuBTwJvycxnW1OeJKmqKjP0+4D5ETEvIo4GVgK9QztExFnAl4Blmfl468uUJDXTNNAz8wXgUuB24CFgfWY+GBFXRcSyerfPA8cB346IbRHRe4jdSZLGSZVDLmTmBmDDsG1XDFl+a4vrkiSNkt8UlaRCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKUSnQI2JxROyMiP6IWNug/ZiI+Fa9/Z6ImNvqQiVJI2sa6BExCbgOWAIsAFZFxIJh3S4BnsjMvwK+APxrqwuVJI2sygx9IdCfmbsz8zngFmD5sD7Lga/Wl28FLoiIaF2ZkqRmqgT6bGDPkPVafVvDPpn5ArAfmDl8RxGxJiL6IqJvYGBgbBVLkhqqEuiNZto5hj5k5k2Z2ZOZPV1dXVXqkyRVVCXQa8CcIevdwN5D9YmIycAM4PetKFCSVE2VQL8PmB8R8yLiaGAl0DusTy/w3vryxcCPM/OgGbokafxMbtYhM1+IiEuB24FJwLrMfDAirgL6MrMX+E/g6xHRz+DMfOV4Fi1JOljTQAfIzA3AhmHbrhiyfAD4+9aWJkkaDb8pKkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVIjo1G3LI2IA+FWbn3YW8Ls2P2e7lDw2KHt8jm3i6sT4XpeZDX/yrWOB3gkR0ZeZPZ2uYzyUPDYoe3yObeI60sbnIRdJKoSBLkmFeKUF+k2dLmAclTw2KHt8jm3iOqLG94o6hi5JJXulzdAlqVgGuiQVoshAj4jFEbEzIvojYm2D9mMi4lv19nsiYm77qxybCmP7aETsiIgHIuJHEfG6TtQ5Vs3GN6TfxRGREXHEXDLWTJWxRcSK+uv3YER8s901jlWF9+VfRsSmiLi//t5c2ok6xyIi1kXE4xGx/RDtERHX1sf+QESc3e4aX5aZRf0DJgGPAK8HjgZ+DiwY1ucfgRvryyuBb3W67haO7XxgWn35QxNlbFXHV+83HbgT2AL0dLruFr5284H7gRPq6yd2uu4Wju0m4EP15QXAo52uexTj+1vgbGD7IdqXAj8EAjgHuKdTtZY4Q18I9Gfm7sx8DrgFWD6sz3Lgq/XlW4ELIiLaWONYNR1bZm7KzKfrq1uA7jbXeDiqvHYAnwU+BxxoZ3GHqcrY3g9cl5lPAGTm422ucayqjC2BV9eXZwB721jfYcnMO4Hfj9BlOfC1HLQFOD4iTmpPdX+uxECfDewZsl6rb2vYJzNfAPYDM9tS3eGpMrahLmFw5jBRNB1fRJwFzMnM77ezsBao8tqdApwSET+JiC0Rsbht1R2eKmP7DLA6ImrABuDD7SmtLUb7dzluJnfiScdZo5n28Gszq/Q5ElWuOyJWAz3AW8a1otYacXwRcRTwBeB97Sqohaq8dpMZPOyyiMFPVndFxGmZ+eQ413a4qoxtFfCVzPy3iDgX+Hp9bP83/uWNuyMmT0qcodeAOUPWuzn4493LfSJiMoMfAUf6SHWkqDI2IuKtwCeBZZn5bJtqa4Vm45sOnAZsjohHGTxe2TtBToxWfV/elpnPZ+YvgZ0MBvyRrsrYLgHWA2Tm3cBUBm9sVYJKf5ftUGKg3wfMj4h5EXE0gyc9e4f16QXeW1++GPhx1s9uHOGajq1+SOJLDIb5RDkG+5IRx5eZ+zNzVmbOzcy5DJ4jWJaZfZ0pd1SqvC+/x+BJbSJiFoOHYHa3tcqxqTK2XwMXAETEqQwG+kBbqxw/vcB76le7nAPsz8zfdqSSTp9BHqez0kuB/2bwzPsn69uuYvCPHwbfTN8G+oF7gdd3uuYWju0O4DFgW/1fb6drbuX4hvXdzAS5yqXiaxfANcAO4BfAyk7X3MKxLQB+wuAVMNuAizpd8yjGdjPwW+B5BmfjlwAfBD445HW7rj72X3TyPelX/yWpECUecpGkVyQDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXi/wGVCEx2HeZk+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='train')\n",
    "plt.plot(loss_test[3:], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanmetz/Documents/EPFL/MA3/The_Little_Turings/ml_math.py:77: RuntimeWarning: overflow encountered in matmul\n",
      "  gradient = -1/N*np.transpose(tx)@e\n"
     ]
    }
   ],
   "source": [
    "max_iter = 200\n",
    "gamma = 1\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_sGD, loss_sGD = least_squares_SGD(y_train,x_train,initial_w,batch_size = 1, \n",
    "                                              max_iters = max_iter, gamma = gamma, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_sGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_LS, loss_LS = least_squares(y_train,x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33942675363884944"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187500, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3394267748814092\n"
     ]
    }
   ],
   "source": [
    "# ridge regression:\n",
    "lambda_ = 0.001\n",
    "N = np.shape(x_train)[1]\n",
    "w_RR = np.linalg.solve(x_train.transpose()@x_train+lambda_*np.identity(N), x_train.transpose()@y_train)\n",
    "loss_RR = compute_MSE(y_train,x_train,w_RR)\n",
    "print(loss_RR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "L = np.linalg.norm(x_train.T@x_train)\n",
    "gamma = 1/L\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_LR_SGD, loss_LR_SGD = logistic_regression(y_train, x_train, initial_w, \n",
    "                                              max_iter, gamma, \n",
    "                                            verbose = False, use_SGD = True, batch_size = 1)\n",
    "w_LR_GD, loss_LR_GD = logistic_regression(y_train, x_train, initial_w, \n",
    "                                              max_iter, gamma, \n",
    "                                          verbose = False, use_SGD = False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Regulated Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "L = np.linalg.norm(x_train.T@x_train)\n",
    "gamma = 1/L\n",
    "lambda_ = 0.7\n",
    "gamma = 2/(L+lambda_)\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_RLR_SGD, loss_LR_SGD = reg_logistic_regression(y_train, x_train, lambda_, initial_w, \n",
    "                                              max_iter, gamma,\n",
    "                                                verbose = False, use_SGD = True)\n",
    "w_RLR_GD, loss_LR_GD = reg_logistic_regression(y_train, x_train, lambda_, initial_w, \n",
    "                                              max_iter, gamma,\n",
    "                                              verbose = False, use_SGD = False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ridge regression gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.74323773e-04 -3.15750557e-04 -1.25959439e-04  5.90320227e-05\n",
      " -7.57037520e-05  3.64250007e-04 -8.35754181e-05 -1.69572756e-06\n",
      " -6.46243823e-05 -1.73346319e-04 -6.97246023e-06  5.14789359e-06\n",
      " -7.65827578e-05  9.31319186e-05 -9.45761853e-08 -2.18238007e-07\n",
      " -1.01283957e-04 -7.90762909e-08  1.78729515e-07 -3.32771364e-05\n",
      "  3.07428971e-07 -2.59806864e-04 -3.33094424e-06  5.54672119e-06\n",
      "  2.37689648e-05  2.37968656e-05 -1.49804492e-04 -7.70376526e-05\n",
      " -7.72381093e-05 -1.65194201e-04] 0.4680313525148537\n"
     ]
    }
   ],
   "source": [
    "max_iter = 100\n",
    "lambda_ = 0.7\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_RR_GD, loss_RR_GD = ridge_regression_GD(y_train, x_train, initial_w, lambda_, max_iter, verbose=False)\n",
    "print(w_RR_GD, loss_RR_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS TEST:\n",
      "GD:  nan\n",
      "GD2:  nan\n",
      "sGD:  nan\n",
      "LS:  0.3405182565064783\n",
      "RR:  0.34051696330272196\n",
      "LR_SGD:  591.3959557130228\n",
      "LR_GD:  591.3959557130228\n",
      "RLR_SGD:  2314.8867062209565\n",
      "RLR_GD:  2314.8867062209565\n"
     ]
    }
   ],
   "source": [
    "print('LOSS TEST:')\n",
    "print('GD: ', compute_MSE(y_test,x_test,w_GD))\n",
    "print('GD2: ', compute_MSE(y_test,x_test,w_GD2))\n",
    "print('sGD: ', compute_MSE(y_test,x_test,w_sGD))\n",
    "print('LS: ', compute_MSE(y_test,x_test,w_LS))\n",
    "print('RR: ', compute_MSE(y_test,x_test,w_RR))\n",
    "print('LR_SGD: ', compute_MSE(y_test,x_test,w_LR_SGD))\n",
    "print('LR_GD: ', compute_MSE(y_test,x_test,w_LR_GD))\n",
    "print('RLR_SGD: ', compute_MSE(y_test,x_test,w_RLR_SGD))\n",
    "print('RLR_GD: ', compute_MSE(y_test,x_test,w_RLR_GD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Choose the weight you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w_GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'result/to_try.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, build_poly(tX_test,degree))\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(build_poly(tX_test,degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
