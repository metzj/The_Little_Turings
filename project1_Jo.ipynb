{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from misc_helpers import *\n",
    "from plot_functions import *\n",
    "from ml_math import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "85667\n",
      "164333\n"
     ]
    }
   ],
   "source": [
    "#check datas and balance of the class\n",
    "N, p = np.shape(tX)\n",
    "print(np.shape(tX))\n",
    "print(len(y[y==1.]))\n",
    "print(len(y[y==-1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.38470e+02,  5.16550e+01,  9.78270e+01, ...,  1.24000e+00,\n",
       "        -2.47500e+00,  1.13497e+02],\n",
       "       [ 1.48754e+02,  2.88620e+01,  1.07782e+02, ...,  1.31000e-01,\n",
       "        -2.76700e+00,  1.79877e+02],\n",
       "       [ 1.54916e+02,  1.04180e+01,  9.47140e+01, ..., -9.99000e+02,\n",
       "        -9.99000e+02,  3.06380e+01],\n",
       "       ...,\n",
       "       [ 1.33457e+02,  7.75400e+01,  8.89890e+01, ..., -9.99000e+02,\n",
       "        -9.99000e+02,  7.09690e+01],\n",
       "       [ 1.30075e+02,  3.91800e+00,  6.67810e+01, ...,  5.78000e-01,\n",
       "        -2.21500e+00,  5.46066e+02],\n",
       "       [ 1.05457e+02,  6.05260e+01,  7.58390e+01, ..., -9.99000e+02,\n",
       "        -9.99000e+02,  4.19920e+01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX[y==1.,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335667, 30)\n",
      "171334\n",
      "164333\n"
     ]
    }
   ],
   "source": [
    "#Over sample\n",
    "y1 = y[y==1.]\n",
    "X1 = tX[y==1.,:]\n",
    "y = np.append(y,y1)\n",
    "tX = np.append(tX,X1,axis=0)\n",
    "print(np.shape(tX))\n",
    "print(len(y[y==1.]))\n",
    "print(len(y[y==-1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change y\n",
    "y = (y+1)/2\n",
    "# normalize X\n",
    "tX = normalize(tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(y, x, ratio, myseed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(myseed)\n",
    "    # generate random indices\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_tr]\n",
    "    x_te = x[index_te]\n",
    "    y_tr = y[index_tr]\n",
    "    y_te = y[index_te]\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "x_train, x_test, y_train, y_test = split_data(y, tX, ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "def sigmoid(t):\n",
    "    \"\"\"apply sigmoid function on t.\"\"\"\n",
    "    return 1.0 / (1.0+np.exp(-t))\n",
    "\n",
    "def calculate_loss(y, tx, w):\n",
    "    \"\"\"compute the cost by negative log likelihood.\"\"\"\n",
    "    s = 0\n",
    "    for n in range(len(y)):\n",
    "        s += np.log(1 + np.exp(np.dot(tx[n,:].T,w))) - y[n]*np.dot(tx[n,:].T,w)\n",
    "    return s \n",
    "\n",
    "def calculate_gradient(y, tx, w):\n",
    "    \"\"\"compute the gradient of loss.\"\"\"\n",
    "    return np.dot(tx.T,sigmoid(np.dot(tx,w))-y)\n",
    "\n",
    "def calculate_hessian(y, tx, w):\n",
    "    \"\"\"return the hessian of the loss function.\"\"\"\n",
    "    N = len(y)\n",
    "    S = np.eye(N)\n",
    "    for n in range(N):\n",
    "        pred = sigmoid(np.dot(tx[n,:].T,w))\n",
    "        S[n,n] = pred*(1-pred)\n",
    "    return tx.T.dot(S.dot(tx))\n",
    "\n",
    "def logistic_regression(y, tx, w, newton = False):\n",
    "    \"\"\"return the loss, gradient, and hessian.\"\"\"\n",
    "    loss = calculate_loss(y, tx, w)\n",
    "    gradient = calculate_gradient(y, tx, w)\n",
    "    if newton:\n",
    "        hess = calculate_hessian(y, tx, w)\n",
    "    else:\n",
    "        hess = 0\n",
    "    return loss, gradient, hess\n",
    "\n",
    "def penalized_logistic_regression(y, tx, w, lambda_, newton = False):\n",
    "    \"\"\"return the loss, gradient, and hessian.\"\"\"\n",
    "    loss, gradient, hess = logistic_regression(y, tx, w, newton)\n",
    "    loss += lambda_/2*np.linalg.norm(w)**2\n",
    "    gradient += lambda_*w\n",
    "    if newton:\n",
    "        hess += lambda_*np.eye(len(w)).dot(w)\n",
    "    else:\n",
    "        hess = 0\n",
    "    return loss, gradient, hess\n",
    "\n",
    "def logistic_regression_ADAM(y , tx, lambda_, maxit, w0, verbose = False):\n",
    "    \"\"\"return w using ADAM\"\"\"\n",
    "    n , p =np.shape(tx)\n",
    "    w = w0\n",
    "    w_prev = w\n",
    "    alpha = 0.1\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    eps = 1E-8\n",
    "    m_prev = 0\n",
    "    v_prev = 0\n",
    "    for k in range(maxit):\n",
    "        g = calculate_gradient(y, tx, w_prev) + lambda_ * w\n",
    "        m = beta1*m_prev + (1-beta1)*g\n",
    "        v = beta2*v_prev + (1-beta2)*g**2\n",
    "        m_hat = m/(1-beta1)\n",
    "        v_hat = v/(1-beta2)\n",
    "        H = np.sqrt(v_hat)+eps\n",
    "        w_next = w - alpha*m_hat/H\n",
    "        w_prev = w\n",
    "        w = w_next\n",
    "        m_prev = m\n",
    "        v_prev = v\n",
    "        #loss = calculate_loss(y, tx, w)\n",
    "        #if not k%10 and verbose:\n",
    "        #if verbose:\n",
    "            #print ('%d : loss = %f, norm(g) = %f'%(k,loss,np.linalg.norm(w)) )\n",
    "            #print(k)\n",
    "    return w\n",
    "\n",
    "def logistic_regression_GD(y , tx, gamma, lambda_, maxit, verbose = False):\n",
    "    \"\"\"return w using ADAM\"\"\"\n",
    "    n , p =np.shape(tx)\n",
    "    w = np.zeros(p)\n",
    "    \n",
    "    for k in range(maxit):\n",
    "        g = calculate_gradient(y, tx, w) + lambda_ * w\n",
    "        w = w - gamma*g\n",
    "        \n",
    "        #loss = calculate_loss(y, tx, w)\n",
    "        #if not k%10 and verbose:\n",
    "        if verbose:\n",
    "            #print ('%d : loss = %f, norm(g) = %f'%(k,loss,np.linalg.norm(w)) )\n",
    "            print(k)\n",
    "    return w\n",
    "\n",
    "def logistic_regression_SGD(y , tx, lambda_, maxit, verbose = False):\n",
    "    \"\"\"return w using ADAM\"\"\"\n",
    "    n , p =np.shape(tx)\n",
    "    w = np.zeros(p)\n",
    "    \n",
    "    for k in range(maxit):\n",
    "        i = randint(0,n),\n",
    "        alpha = (n/2)/(k+(n/2))\n",
    "        g = calculate_gradient(y[i], tx[i,:], w) + lambda_ * w\n",
    "        w = w - alpha * g\n",
    "        \n",
    "        #if not k%100 and verbose:\n",
    "            #print(k)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46533.69588139893"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate logistic_regression_SGD\n",
    "lambda_ = 0.5\n",
    "w1= logistic_regression_SGD(y_train ,x_train, lambda_, 2*N)\n",
    "calculate_loss(y_test, x_test, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42900.3007895025"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.5\n",
    "w2 = logistic_regression_ADAM(y_train ,x_train, lambda_, 2000)\n",
    "calculate_loss(y_test, x_test, w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "def compute_error(y,tX,w):\n",
    "    erre = np.dot(tX,w)\n",
    "    e = y - np.dot(tX,w)\n",
    "    return 0\n",
    "    \n",
    "def cross_validation(y, x, k_fold, solver = 'LS',stoch = True,lambda_ = 0, maxit = 1):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    seed = 1\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    mse_tr = 0\n",
    "    mse_te = 0\n",
    "    w_0 = 0\n",
    "    p = np.shape(x)[1]\n",
    "    w0 = np.zeros(p)\n",
    "    w_s = np.zeros(p)\n",
    "    \n",
    "    for k in range(k_fold):\n",
    "        # get k'th subgroup in test, others in train:\n",
    "        test_indices = k_indices[k]\n",
    "        train_indices = np.delete(k_indices,k,0).flatten()\n",
    "        x_tr = x[train_indices]\n",
    "        y_tr = y[train_indices]\n",
    "        x_te = x[test_indices]\n",
    "        y_te = y[test_indices]\n",
    "\n",
    "        # Least squares:\n",
    "        if solver == 'LS':\n",
    "            w, loss = least_squares(y_tr, x_tr)\n",
    "        elif solver == 'RR':\n",
    "            w, loss = ridge_regression(y_tr, x_tr, lambda_)\n",
    "        elif solver == 'LR':\n",
    "            w = logistic_regression_ADAM(y_tr ,x_tr, lambda_, maxit, w0)\n",
    "        else:\n",
    "            raise('Error')\n",
    "\n",
    "        # Train loss\n",
    "        b = np.dot(x_tr, w)\n",
    "        b[b>0] = 1.0\n",
    "        b[b<0] = 0.0\n",
    "        loss_tr = np.linalg.norm(y_tr-b,1)/ len(y_tr)\n",
    "        #validation loss\n",
    "        b = np.dot(x_te, w)\n",
    "        b[b>0] = 1.0\n",
    "        b[b<0] = 0.0\n",
    "        loss_te = np.linalg.norm(y_te-b,1)/ len(y_te)\n",
    "    \n",
    "        mse_tr += loss_tr/k_fold\n",
    "        mse_te += loss_te/k_fold\n",
    "        w_s += w/k_fold\n",
    "        w_0 = w\n",
    "    \n",
    "    return mse_tr, mse_te, w_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature expension and choose best with lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree, linear = False):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    if linear == False:\n",
    "        D = len(x[0,:])\n",
    "        N = len(x[:,0])\n",
    "        new_x = np.ones((N,1)) #add bias\n",
    "        if degree>=1:\n",
    "            for i in range(1,degree+1):\n",
    "                new_x = np.append(new_x,x**i,axis=1) \n",
    "        return new_x\n",
    "    else:\n",
    "        m = np.zeros((len(x),degree+1))\n",
    "        for j in range(degree+1):\n",
    "            m[:,j] = x**j\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(335667, 391)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_model = build_poly(tX[:,1],0,linear ='True')\n",
    "good_feat = range(p)\n",
    "degrees = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "for feat in good_feat:\n",
    "    print(feat)\n",
    "    for deg in degrees:\n",
    "        tX_model = np.append(tX_model, np.array([tX[:,feat]**deg]).T,axis=1)\n",
    "    tX_model = np.append(tX_model, np.array([np.arctan(tX[:,feat])]).T,axis=1)\n",
    "    #tX_model = np.append(tX_model, np.array([np.sin(tX[:,feat])]).T,axis=1)\n",
    "    #tX_model = np.append(tX_model, np.array([np.cos(tX[:,feat])]).T,axis=1)\n",
    "np.shape(tX_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "#test the model\n",
    "n,p = np.shape(tX_model)\n",
    "losses=np.zeros((30,2))\n",
    "lbds = np.logspace(-4,0,30)\n",
    "w_s = np.zeros((p,30))\n",
    "k = 0\n",
    "for lbd in lbds:\n",
    "    print(k)\n",
    "    loss_tr, loss_te, w = cross_validation(y,tX_model, 4, solver = 'LR', stoch =False, lambda_=lbd, maxit = 50)\n",
    "    losses[k,0] = loss_tr\n",
    "    losses[k,1] = loss_te\n",
    "    w_s[:,k] = w\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-17f201b98233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature %i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(losses[:,0])\n",
    "plt.plot(losses[:,1])\n",
    "plt.title('Feature %i')\n",
    "plt.legend(['Train loss','Validation loss'])\n",
    "plt.show()\n",
    "plt.savefig('391_feat.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20433597178569418"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the best lambda and best w\n",
    "w_1 = w_s[:,24]\n",
    "lambda_1 = lbds[20] \n",
    "lambda_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â Build the model for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "(568238, 391)\n",
      "(391,)\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "tX_model_test = build_poly(tX_test[:,1],0,linear ='True')\n",
    "n,p = np.shape(tX_test)\n",
    "good_feat = range(p)\n",
    "degrees = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "for feat in good_feat:\n",
    "    print(feat)\n",
    "    for deg in degrees:\n",
    "        tX_model_test = np.append(tX_model_test, np.array([tX_test[:,feat]**deg]).T,axis=1)\n",
    "    tX_model_test = np.append(tX_model_test, np.array([np.arctan(tX_test[:,feat])]).T,axis=1)\n",
    "    #tX_model = np.append(tX_model, np.array([np.sin(tX[:,feat])]).T,axis=1)\n",
    "    #tX_model = np.append(tX_model, np.array([np.cos(tX[:,feat])]).T,axis=1)\n",
    "print(np.shape(tX_model_test))\n",
    "print(np.shape(w_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/proj1_jo_391_1.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w_1, tX_model_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add successively features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test time for few features\n",
    "tX_model_2 = tX[:,[1,2]]\n",
    "n, p = np.shape(tX_model_2)\n",
    "w = logistic_regression_ADAM(y ,tX_model_2, 0, 500, w0 = np.zeros(p))\n",
    "#let's take 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 10\n",
      "9 11\n",
      "10 12\n",
      "11 13\n",
      "12 14\n",
      "13 15\n",
      "14 16\n",
      "15 17\n",
      "16 18\n",
      "17 19\n",
      "18 20\n",
      "19 21\n",
      "20 22\n",
      "21 23\n",
      "22 24\n",
      "23 25\n",
      "24 26\n",
      "25 27\n",
      "26 28\n",
      "27 29\n",
      "28 30\n",
      "29 31\n"
     ]
    }
   ],
   "source": [
    "#Alogrithm who will add the feature with the degree only if it improves the model.\n",
    "good_feat = range(30)\n",
    "degrees = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "#initialize model\n",
    "tX_model = build_poly(tX[:,1],0,linear ='True')\n",
    "w_model = np.ones(1)\n",
    "model = np.zeros((1,2))\n",
    "losses = np.array([])\n",
    "losses_tr = np.array([])\n",
    "for feat in good_feat:\n",
    "    print(feat, np.shape(tX_model)[1])\n",
    "    loss = 10000000\n",
    "    for deg in degrees:\n",
    "        tX_try = np.append(tX_model, np.array([tX[:,feat]**deg]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y,tX_try, 4, solver = 'LR', stoch =False, lambda_=0, maxit = 1000)\n",
    "        if loss_te < loss*0.95:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),deg]]),axis=0)\n",
    "            losses = np.append(losses,loss_te)\n",
    "            losses_tr = np.append(losses_tr,loss_tr)\n",
    "            w_model = w\n",
    "    #degree -1,-2\n",
    "    if len(tX[tX[:,1]==0]) == 0:\n",
    "        tX_try = np.append(tX_model, np.array([tX[:,feat]**-1]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y,tX_try, 4, solver = 'LR', stoch =False, lambda_=0, maxit = 500)\n",
    "        if loss_te < loss*0.95:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),-1]]),axis=0)\n",
    "            losses = np.append(losses,loss_te)\n",
    "            losses_tr = np.append(losses_tr,loss_tr)\n",
    "            w_model = w\n",
    "        tX_try = np.append(tX_model, np.array([tX[:,feat]**-2]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y,tX_try, 4, solver = 'LR', stoch =False, lambda_=0, maxit = 500)\n",
    "        if loss_te < loss*0.95:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),-2]]),axis=0)\n",
    "            losses = np.append(losses,loss_te)\n",
    "            losses_tr = np.append(losses_tr,loss_tr)\n",
    "            w_model = w\n",
    "        #degree -1/2 -1/3\n",
    "        if len(tX[tX[:,1]<0]) == 0:\n",
    "            tX_try = np.append(tX_model, np.array([tX[:,feat]**-1/2]).T,axis=1)\n",
    "            loss_tr, loss_te, w = cross_validation(y,tX_try, 4, solver = 'LR', stoch =False, lambda_=0, maxit = 500)\n",
    "            if loss_te < loss*0.95:\n",
    "                loss = loss_te\n",
    "                tX_model = tX_try.copy()\n",
    "                #save model\n",
    "                model = np.append(model,np.array([[int(feat),-1/2]]),axis=0)\n",
    "                losses = np.append(losses,loss_te)\n",
    "                losses_tr = np.append(losses_tr,loss_tr)\n",
    "                w_model = w\n",
    "            tX_try = np.append(tX_model, np.array([tX[:,feat]**-1/3]).T,axis=1)\n",
    "            loss_tr, loss_te, w = cross_validation(y,tX_try, 4, solver = 'LR', stoch =False, lambda_=0, maxit = 500)\n",
    "            if loss_te < loss*0.95:\n",
    "                loss = loss_te\n",
    "                tX_model = tX_try.copy()\n",
    "                #save model\n",
    "                model = np.append(model,np.array([[int(feat),-1/3]]),axis=0)\n",
    "                losses = np.append(losses,loss_te)\n",
    "                losses_tr = np.append(losses_tr,loss_tr)\n",
    "                w_model = w\n",
    "    #degree 1/2 1/3\n",
    "    if len(tX[tX[:,1]<0]) == 0:\n",
    "        tX_try = np.append(tX_model, np.array([tX[:,feat]**1/2]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y,tX_try, 4, solver = 'LR', stoch =False, lambda_=0, maxit = 500)\n",
    "        if loss_te < loss*0.95:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),1/2]]),axis=0)\n",
    "            losses = np.append(losses,loss_te)\n",
    "            losses_tr = np.append(losses_tr,loss_tr)\n",
    "            w_model = w\n",
    "        tX_try = np.append(tX_model, np.array([tX[:,feat]**1/3]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y,tX_try, 4, solver = 'LR', stoch =False, lambda_=0, maxit = 500)\n",
    "        if loss_te < loss*0.95:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),1/3]]),axis=0)\n",
    "            losses = np.append(losses,loss_te)\n",
    "            losses_tr = np.append(losses_tr,loss_tr)\n",
    "            w_model = w\n",
    "        \n",
    "\n",
    "#Save model\n",
    "model_2 = model\n",
    "loss_2 = losses[-1]\n",
    "w_2 = w_model\n",
    "tX_2 = tX_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.title('losses')\n",
    "plt.show()\n",
    "plt.savefig('add_feat_3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model very well with all the datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,p = np.shape(tX_2)\n",
    "w_2 = logistic_regression_ADAM(y ,tX_2, 0, 10000, np.zeros(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct the x_test based on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_2[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "0 1.0\n",
      "1 1.0\n",
      "2 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(568238, 4)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now Build the tX train data set\n",
    "\n",
    "#start with bias\n",
    "tX_model_test = build_poly(tX_test[:,1],0,linear ='True')\n",
    "tX_test = normalize(tX_test)\n",
    "#create model\n",
    "for feat, deg in model:\n",
    "    feat = int(float(feat.item()))\n",
    "    print(feat,deg)\n",
    "    if deg == 'arctan':\n",
    "        tX_model_test = np.append(tX_model_test, np.array([np.arctan(tX_test[:,feat])]).T,axis=1)\n",
    "    elif deg == 'cos':\n",
    "        tX_model_test = np.append(tX_model_test, np.array([np.cos(tX_test[:,feat])]).T,axis=1)\n",
    "    elif deg =='sin':\n",
    "        tX_model_test = np.append(tX_model_test, np.array([np.sin(tX_test[:,feat])]).T,axis=1)\n",
    "    else :\n",
    "        deg = float(deg)\n",
    "        if deg == 0.5 or deg == 1/3 or deg == -1/2 or deg == -1/3:\n",
    "            tX_model_test = np.append(tX_model_test, np.array([np.abs(tX_test[:,feat])**deg]).T,axis=1)\n",
    "        elif deg != 0:\n",
    "            tX_model_test = np.append(tX_model_test, np.array([tX_test[:,feat]**deg]).T,axis=1)\n",
    "np.shape(tX_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/proj1_jo_add_feat_4.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w_2[:4], tX_model_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The experiment 1 has only limited number of feature and deg=[1,6]\n",
    "Exp2: has all feature but not special deg, maxit=500, 64 features, 0.721 C-A, 0.622 F1 \n",
    "0 0.0\n",
    "0 1.0\n",
    "1 1.0\n",
    "1 2.0\n",
    "1 6.0\n",
    "1 6.0\n",
    "2 1.0\n",
    "2 2.0\n",
    "2 6.0\n",
    "2 6.0\n",
    "3 1.0\n",
    "3 2.0\n",
    "3 3.0\n",
    "3 6.0\n",
    "3 6.0\n",
    "4 1.0\n",
    "4 2.0\n",
    "5 1.0\n",
    "5 2.0\n",
    "6 1.0\n",
    "7 1.0\n",
    "7 6.0\n",
    "7 6.0\n",
    "8 1.0\n",
    "8 4.0\n",
    "8 5.0\n",
    "8 6.0\n",
    "8 6.0\n",
    "9 1.0\n",
    "10 1.0\n",
    "10 2.0\n",
    "10 6.0\n",
    "10 6.0\n",
    "11 1.0\n",
    "11 2.0\n",
    "12 1.0\n",
    "13 1.0\n",
    "13 2.0\n",
    "13 6.0\n",
    "13 6.0\n",
    "14 1.0\n",
    "15 1.0\n",
    "16 1.0\n",
    "16 6.0\n",
    "16 6.0\n",
    "17 1.0\n",
    "18 1.0\n",
    "19 1.0\n",
    "19 2.0\n",
    "19 3.0\n",
    "19 6.0\n",
    "19 6.0\n",
    "20 1.0\n",
    "21 1.0\n",
    "22 1.0\n",
    "23 1.0\n",
    "24 1.0\n",
    "25 1.0\n",
    "26 1.0\n",
    "27 1.0\n",
    "27 2.0\n",
    "28 1.0\n",
    "28 2.0\n",
    "29 1.0\n",
    "Exp3: all feature, deg=[1,12], special deg, maxit=1000, loss_te<0.95*loss , 0.342 C-A, 0.51 F1\n",
    "0 0.0\n",
    "0 1.0\n",
    "1 1.0\n",
    "2 1.0\n",
    "3 1.0\n",
    "4 1.0\n",
    "5 1.0\n",
    "6 1.0\n",
    "7 1.0\n",
    "7 0.5\n",
    "8 1.0\n",
    "9 1.0\n",
    "10 1.0\n",
    "11 1.0\n",
    "12 1.0\n",
    "13 1.0\n",
    "14 1.0\n",
    "15 1.0\n",
    "16 1.0\n",
    "17 1.0\n",
    "18 1.0\n",
    "19 1.0\n",
    "20 1.0\n",
    "21 1.0\n",
    "22 1.0\n",
    "23 1.0\n",
    "24 1.0\n",
    "25 1.0\n",
    "26 1.0\n",
    "27 1.0\n",
    "28 1.0\n",
    "29 1.0\n",
    "Exp4: Only 4 first of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'result/to_try.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, build_poly(tX_test,degree))\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
