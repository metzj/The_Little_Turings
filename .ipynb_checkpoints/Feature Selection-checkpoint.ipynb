{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from misc_helpers import *\n",
    "from plot_functions import *\n",
    "from ml_math import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm = normalize(y)\n",
    "tX_norm = normalize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def cross_validation(y, x, k_fold, solver = 'LS',lambda_ = 0):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    seed = 1\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    mse_tr = 0\n",
    "    mse_te = 0\n",
    "    for k in range(k_fold):\n",
    "        # get k'th subgroup in test, others in train:\n",
    "        test_indices = k_indices[k]\n",
    "        train_indices = np.delete(k_indices,k,0).flatten()\n",
    "        x_tr = x[train_indices]\n",
    "        y_tr = y[train_indices]\n",
    "        x_te = x[test_indices]\n",
    "        y_te = y[test_indices]\n",
    "\n",
    "        # Least squares:\n",
    "        if solver == 'LS':\n",
    "            w, loss = least_squares(y_tr, x_tr)\n",
    "        elif solver == 'RR':\n",
    "            w, loss = ridge_regression(y_tr, x_tr, lambda_)\n",
    "        else:\n",
    "            raise('Error')\n",
    "\n",
    "        # calculate the loss for train and test data: \n",
    "        loss_tr = compute_MSE(y_tr, x_tr, w)\n",
    "        loss_te = compute_MSE(y_te, x_te, w)\n",
    "    \n",
    "        mse_tr += loss_tr/k_fold\n",
    "        mse_te += loss_te/k_fold\n",
    "        \n",
    "    \n",
    "    return mse_tr, mse_te, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some crazy feature selection here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree, linear = False):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    if linear == False:\n",
    "        D = len(x[0,:])\n",
    "        N = len(x[:,0])\n",
    "        new_x = np.ones((N,1)) #add bias\n",
    "        if degree>=1:\n",
    "            for i in range(1,degree+1):\n",
    "                new_x = np.append(new_x,x**i,axis=1) \n",
    "        return new_x\n",
    "    else:\n",
    "        m = np.zeros((len(x),degree+1))\n",
    "        for j in range(degree+1):\n",
    "            m[:,j] = x**j\n",
    "        return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the noise level. Everything that we add should beat this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.45049216308621154, 0.45050112681244814, array([-0.31568]))\n",
      "(0.45049216308621154, 0.45050112681244814, array([-0.31568]))\n"
     ]
    }
   ],
   "source": [
    "#only constant feature\n",
    "tX0 = build_poly(tX,0)\n",
    "print(cross_validation(y,tX0,4))\n",
    "#only constant feature\n",
    "tX0 = build_poly(tX_norm,0)\n",
    "print(cross_validation(y,tX0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test every degree for every feature\n",
    "n,p = np.shape(tX)\n",
    "loss = []\n",
    "good_feat = []\n",
    "min_loss = np.ones(p)*10000\n",
    "min_deg = np.zeros(p)\n",
    "for deg in [0,1,2,3,4,5,6,7,8,9,10]:\n",
    "    for i in range(p):\n",
    "        tX_ = build_poly(tX[:,i],deg, linear=True)\n",
    "        loss_tr,loss_te,w = cross_validation(y,tX_,5)\n",
    "        if loss_te<min_loss[i]:\n",
    "            min_loss[i] = loss_te\n",
    "            min_deg[i] = deg\n",
    "        if loss_te < 0.45:\n",
    "            good_feat.append((i,deg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  4,  5,  6,  9, 10, 11, 12, 13]),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all of these are good features\n",
    "id_min_loss = np.where(min_loss < 0.43)\n",
    "id_min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.00000000e+00,  1.38470000e+02, ...,\n",
       "         1.06523904e+03,  3.47672719e+04,  1.13473422e+06],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.60937000e+02, ...,\n",
       "         1.76517620e+03,  7.41621127e+04,  3.11584700e+06],\n",
       "       [ 1.00000000e+00,  1.00000000e+00, -9.99000000e+02, ...,\n",
       "         1.03387972e+03,  3.32433684e+04,  1.06890727e+06],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.05457000e+02, ...,\n",
       "         1.26992450e+03,  4.52550293e+04,  1.61270823e+06],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  9.49510000e+01, ...,\n",
       "         7.80867136e+02,  2.18205512e+04,  6.09753484e+05],\n",
       "       [ 1.00000000e+00,  1.00000000e+00, -9.99000000e+02, ...,\n",
       "         1.84925801e+03,  7.95236422e+04,  3.41975518e+06]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate all good feature in tX0\n",
    "tX0 = build_poly(tX,0)\n",
    "for i in  id_min_loss[0]:\n",
    "    deg = int(min_deg[i])\n",
    "    tX0 = np.append(tX0, build_poly(tX[:,i], deg, linear=True),1)\n",
    "tX0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-10, 0, 30)\n",
    "rmse_tr = []\n",
    "rmse_te = []\n",
    "mse_te_min = 10000\n",
    "w0 = np.ones((p))\n",
    "for lambda_ in lambdas:\n",
    "    mse_tr, mse_te, w = cross_validation(y,tX0,5,solver = 'RR',lambda_ = lambda_)\n",
    "    rmse_tr = np.append(rmse_tr,mse_tr)\n",
    "    rmse_te = np.append(rmse_te,mse_te)\n",
    "    if mse_te < mse_te_min:\n",
    "        w0 = w\n",
    "        mse_te_min = mse_te\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Test for AIcrowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tX_test = normalize(tX_test)\n",
    "#concatenate all good feature in tX0\n",
    "tX_test_0 = build_poly(tX_test,0)\n",
    "for i in  id_min_loss[0]:\n",
    "    deg = int(min_deg[i])\n",
    "    tX_test_0 = np.append(tX_test_0, build_poly(tX_test[:,i], deg, linear=True),1)\n",
    "np.shape(tX_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'result/feature_selection.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w0, tX_test_0)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from Remi's conclusion. Which is to take only the feature.\\\n",
    "1, 2, 4, 5, 7, 10, 11, 13, 14, 22, 23, 29, 30 (the id in feature is one less)\\\n",
    "First, delete where there is undefined feature. We will use:\\\n",
    "2, 4, 10, 11, 14, 22, 23, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see for each, which of the degree is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alogrithm who will add the feature with the degree only if it improves the model.\n",
    "good_feat = range(30)\n",
    "degrees = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "losses = np.zeros((len(degrees),len(good_feat)))\n",
    "#initialize model\n",
    "tX_model = build_poly(tX[:,1],1,linear ='True')\n",
    "for feat in good_feat:\n",
    "    loss = 10000\n",
    "    for deg in degrees:\n",
    "        tX0 = build_poly(tX[:,feat],deg,linear ='True')\n",
    "        loss_tr, loss_te, w = cross_validation(y, tX0, 5, solver = 'LS')\n",
    "        if loss_te > 0.45:\n",
    "            loss_te = 0.45\n",
    "        losses[deg,0] = deg\n",
    "        losses[deg,1] = loss_te\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(losses[:,0],losses[:,1])\n",
    "    plt.title('Feature %i' %feat)\n",
    "    plt.xticks(losses[:,0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following algorithm add a feature, elevate to a power p, to the model if it improves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Alogrithm who will add the feature with the degree only if it improves the model.\n",
    "good_feat = [1,3,9,10,13,21,22,29]\n",
    "degrees = [1,2,3,4,5,6,1/2,1/3,1/4,1/5,1/6,\\\n",
    "          -1,-2,-3,-4,-5,-1/2,-1/3,-1/4,-1/5,-1/6]\n",
    "#initialize model\n",
    "tX_model = build_poly(tX[:,1],0,linear ='True')\n",
    "w_model = np.ones(1)\n",
    "model = np.zeros((1,2))\n",
    "losses = np.array([])\n",
    "losses_tr = np.array([])\n",
    "for feat in good_feat:\n",
    "    print(feat)\n",
    "    loss = 10000\n",
    "    for deg in degrees:\n",
    "        tX_try = np.append(tX_model, np.array([tX_norm[:,feat]**deg]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "        if loss_te < loss:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),deg]]),axis=0)\n",
    "            losses = np.append(losses,loss)\n",
    "            losses_tr = np.append(losses_tr,loss_tr)\n",
    "            w_model = w\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(losses)\n",
    "plt.plot(losses_tr)\n",
    "plt.title('losses')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Save model\n",
    "model_1 = model\n",
    "loss_1 = losses[-1]\n",
    "w_1 = w_model\n",
    "tX_1 = tX_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the loss decrease well. We should use this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With trigonometrie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see that it's good functionning, let's take all feature where it cannot be singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Alogrithm who will add the feature with the degree only if it improves the model.\n",
    "good_feat = [1,2,3,7,8,9,10,11,13,14,15,16,17,18,19,20,21,22,29]\n",
    "degrees = [1,2,3,4,5,6,1/2,1/3,1/4,1/5,1/6,\\\n",
    "          -1,-2,-3,-4,-5,-6,-1/2,-1/3,-1/4,-1/5,-1/6]\n",
    "#initialize model\n",
    "tX_model = build_poly(tX[:,1],0,linear ='True')\n",
    "w_model = np.ones(1)\n",
    "model = np.zeros((1,2))\n",
    "losses = np.array([])\n",
    "for feat in good_feat:\n",
    "    print(feat)\n",
    "    loss = 10000\n",
    "    # calucate a polynomial\n",
    "    for deg in degrees:\n",
    "        tX_try = np.append(tX_model, np.array([tX_norm[:,feat]**deg]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "        if loss_te < loss:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),deg]]),axis=0)\n",
    "            losses = np.append(losses,loss)\n",
    "            w_model = w\n",
    "    #calculate arctan\n",
    "    tX_try = np.append(tX_model, np.array([np.arctan(tX_norm[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'arctan']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w\n",
    "    #calculate sinus\n",
    "    tX_try = np.append(tX_model, np.array([np.sin(tX[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'sin']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w\n",
    "    #calculate cosinus\n",
    "    tX_try = np.append(tX_model, np.array([np.cos(tX[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'cos']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w              \n",
    "            \n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(losses)\n",
    "plt.title('losses')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_2 = model\n",
    "loss_2 = losses[-1]\n",
    "w_2 = w_model\n",
    "tX_2 = tX_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following takes all features advised by RÃ©mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Alogrithm who will add the feature with the degree only if it improves the model.\n",
    "good_feat = [0, 1, 3, 4, 6, 9, 10, 12, 13, 21, 22, 28, 29]\n",
    "degrees = [1,2,3,4,5,6,1/2,1/3,1/4,1/5,1/6,\\\n",
    "          -1,-2,-3,-4,-5,-6,-1/2,-1/3,-1/4,-1/5,-1/6]\n",
    "#initialize model\n",
    "tX_model = build_poly(tX[:,1],0,linear ='True')\n",
    "w_model = np.ones(1)\n",
    "model = np.zeros((1,2))\n",
    "losses = np.array([])\n",
    "for feat in good_feat:\n",
    "    print(feat)\n",
    "    loss = 10000\n",
    "    # calucate a polynomial\n",
    "    for deg in degrees:\n",
    "        tX_try = np.append(tX_model, np.array([tX_norm[:,feat]**deg]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "        if loss_te < loss:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),deg]]),axis=0)\n",
    "            losses = np.append(losses,loss)\n",
    "            w_model = w\n",
    "    #calculate arctan\n",
    "    tX_try = np.append(tX_model, np.array([np.arctan(tX_norm[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'arctan']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w\n",
    "    #calculate sinus\n",
    "    tX_try = np.append(tX_model, np.array([np.sin(tX[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'sin']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w\n",
    "    #calculate cosinus\n",
    "    tX_try = np.append(tX_model, np.array([np.cos(tX[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'sin']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w              \n",
    "            \n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(losses)\n",
    "plt.title('losses')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_3 = model\n",
    "loss_3 = losses[-1]\n",
    "w_3 = w_model\n",
    "tX_3 = tX_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try all feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Alogrithm who will add the feature with the degree only if it improves the model.\n",
    "good_feat = range(30)\n",
    "degrees = [1,2,3,4,5,6,1/2,1/3,1/4,\\\n",
    "          -1,-2,-3,-4,-5,-6,-1/2,-1/3,-1/4]\n",
    "#initialize model\n",
    "tX_model = build_poly(tX_norm[:,1],0,linear ='True')\n",
    "w_model = np.ones(1)\n",
    "model = np.zeros((1,2))\n",
    "losses = np.array([])\n",
    "for feat in good_feat:\n",
    "    print(feat)\n",
    "    loss = 10000\n",
    "    # calucate a polynomial\n",
    "    for deg in degrees:\n",
    "        tX_try = np.append(tX_model, np.array([tX_norm[:,feat]**deg]).T,axis=1)\n",
    "        loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "        if loss_te < loss:\n",
    "            loss = loss_te\n",
    "            tX_model = tX_try.copy()\n",
    "            #save model\n",
    "            model = np.append(model,np.array([[int(feat),deg]]),axis=0)\n",
    "            losses = np.append(losses,loss)\n",
    "            w_model = w\n",
    "    #calculate arctan\n",
    "    tX_try = np.append(tX_model, np.array([np.arctan(tX_norm[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'arctan']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w\n",
    "    #calculate sinus\n",
    "    tX_try = np.append(tX_model, np.array([np.sin(tX[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'sin']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w\n",
    "    #calculate cosinus\n",
    "    tX_try = np.append(tX_model, np.array([np.cos(tX[:,feat])]).T,axis=1)\n",
    "    loss_tr, loss_te, w = cross_validation(y, tX_try, 5, solver = 'LS')\n",
    "    if loss_te < loss:\n",
    "        loss = loss_te\n",
    "        tX_model = tX_try.copy()\n",
    "        #save model\n",
    "        model = np.append(model,np.array([[int(feat),'cos']]),axis=0)\n",
    "        losses = np.append(losses,loss)\n",
    "        w_model = w              \n",
    "            \n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(losses)\n",
    "plt.title('losses')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_4 = model\n",
    "loss_4 = losses[-1]\n",
    "w_4 = w_model\n",
    "tX_4 = tX_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild model for another X to evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('loss_1: ', loss_1, 'shape :', np.shape(model_1))\n",
    "print('loss_2: ', loss_2, 'shape :', np.shape(model_2))\n",
    "print('loss_3: ', loss_3, 'shape :', np.shape(model_3))\n",
    "print('loss_4: ', loss_4, 'shape :', np.shape(model_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#choose the best model\n",
    "model = model_3\n",
    "\n",
    "#start with bias\n",
    "tX_model = build_poly(tX[:,1],0,linear ='True')\n",
    "tX_norm = normalize(tX)\n",
    "#create model\n",
    "for feat, deg in model:\n",
    "    feat = int(float(feat.item()))\n",
    "    print(feat,deg)\n",
    "    if deg == 'arctan':\n",
    "        tX_model = np.append(tX_model, np.array([np.arctan(tX_norm[:,feat])]).T,axis=1)\n",
    "    elif deg == 'cos':\n",
    "        tX_model = np.append(tX_model, np.array([np.cos(tX[:,feat])]).T,axis=1)\n",
    "    elif deg =='sin':\n",
    "        tX_model = np.append(tX_model, np.array([np.sin(tX[:,feat])]).T,axis=1)\n",
    "    else :\n",
    "        deg = float(deg)\n",
    "        if deg != 0:\n",
    "            tX_model = np.append(tX_model, np.array([tX_norm[:,feat]**deg]).T,axis=1)\n",
    "\n",
    "#train weights\n",
    "weights, loss = least_squares(y, tX_model)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Build the tX train data set\n",
    "\n",
    "#start with bias\n",
    "tX_model_test = build_poly(tX_test[:,1],0,linear ='True')\n",
    "tX_test_norm = normalize(tX_test)\n",
    "#create model\n",
    "for feat, deg in model:\n",
    "    feat = int(float(feat.item()))\n",
    "    print(feat,deg)\n",
    "    if deg == 'arctan':\n",
    "        tX_model_test = np.append(tX_model_test, np.array([np.arctan(tX_test_norm[:,feat])]).T,axis=1)\n",
    "    elif deg == 'cos':\n",
    "        tX_model_test = np.append(tX_model_test, np.array([np.cos(tX_test[:,feat])]).T,axis=1)\n",
    "    elif deg =='sin':\n",
    "        tX_model_test = np.append(tX_model_test, np.array([np.sin(tX_test[:,feat])]).T,axis=1)\n",
    "    else :\n",
    "        deg = float(deg)\n",
    "        if deg != 0:\n",
    "            tX_model_test = np.append(tX_model_test, np.array([tX_test_norm[:,feat]**deg]).T,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/feature_selection_best_30.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_model_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML_course] *",
   "language": "python",
   "name": "conda-env-ML_course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
