{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from misc_helpers import *\n",
    "from plot_functions import *\n",
    "from ml_math import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm = normalize(y)\n",
    "tX_norm = normalize(tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension lifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(tx,degree):\n",
    "    D = len(tx[0,:])\n",
    "    N = len(tx[:,0])\n",
    "    new_x = np.ones((N,1)) #add bias\n",
    "    if degree>=1:\n",
    "        for i in range(1,degree+1):\n",
    "            new_x = np.append(new_x,tx**i,axis=1) \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 211)\n"
     ]
    }
   ],
   "source": [
    "#Run this box only once!!\n",
    "degree = 7\n",
    "new_train = build_poly(tX_norm,degree)\n",
    "print(np.shape(new_train))\n",
    "tX = new_train #ECRASE LES DONNEES!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(y, x, ratio, myseed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(myseed)\n",
    "    # generate random indices\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_tr]\n",
    "    x_te = x[index_te]\n",
    "    y_tr = y[index_tr]\n",
    "    y_te = y[index_te]\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.75\n",
    "x_train, x_test, y_train, y_test = split_data(y, tX, ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "gamma = 1\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_GD, loss_GD = least_squares_GD(y_train, x_train, initial_w, max_iter, gamma, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_test = np.array([1e7,1e6,1e5])\n",
    "losses = []\n",
    "i = 2\n",
    "N_w = len(x_train[1,:])\n",
    "w_GD2 = np.zeros(N_w)\n",
    "max_i = 10\n",
    "while ((loss_test[i-2]>loss_test[i-1] or loss_test[i-1]>loss_test[i]) )and i<=max_i:\n",
    "    max_iter = 50\n",
    "    gamma = 1\n",
    "    N_w = len(x_train[1,:])\n",
    "    w_GD2, loss_GD =least_squares_GD(y_train,x_train,w_GD2,max_iters = max_iter,gamma = gamma,verbose = False)\n",
    "    losses = np.append(losses,loss_GD)\n",
    "    loss_test = np.append(loss_test,compute_MSE(y_test,x_test,w_GD2))\n",
    "    i=i+1\n",
    "    print('i=',i,' gamma=',gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, label='train')\n",
    "plt.plot(loss_test[3:], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 200\n",
    "gamma = 1\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_sGD, loss_sGD = least_squares_SGD(y_train,x_train,initial_w,batch_size = 1, \n",
    "                                              max_iters = max_iter, gamma = gamma, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_LS, loss_LS = least_squares(y_train,x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression:\n",
    "lambda_ = 0.001\n",
    "N = np.shape(x_train)[1]\n",
    "w_RR = np.linalg.inv(x_train.transpose()@x_train+lambda_*np.identity(N))@x_train.transpose()@y_train\n",
    "loss_RR = compute_MSE(y_train,x_train,w_RR)\n",
    "print(loss_RR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "gamma = 1\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_LR_SGD, loss_LR_SGD = logistic_regression(y_train, x_train, initial_w, \n",
    "                                              max_iter, gamma, \n",
    "                                            verbose = False, use_SGD = True, batch_size = 1)\n",
    "w_LR_GD, loss_LR_GD = logistic_regression(y_train, x_train, initial_w, \n",
    "                                              max_iter, gamma, \n",
    "                                          verbose = False, use_SGD = False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Regulated Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "gamma = 1\n",
    "lambda_ = 0.7\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_RLR_SGD, loss_LR_SGD = reg_logistic_regression(y_train, x_train, lambda_, initial_w, \n",
    "                                              max_iter, gamma,\n",
    "                                                verbose = False, use_SGD = True)\n",
    "w_RLR_GD, loss_LR_GD = reg_logistic_regression(y_train, x_train, lambda_, initial_w, \n",
    "                                              max_iter, gamma,\n",
    "                                              verbose = False, use_SGD = False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ridge regression gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.85686114e-01  6.88208960e-04 -8.55737638e-04 -3.49284320e-04\n",
      "  1.34381379e-04  5.20013064e-04  6.34761254e-04  5.18164901e-04\n",
      " -3.41455771e-04 -2.72116546e-04 -5.73495539e-05 -5.89302439e-04\n",
      "  7.78697718e-04  5.19417975e-04 -3.03664578e-06 -1.35514759e-07\n",
      " -9.71319898e-06 -3.74526720e-04  1.04280305e-05  1.65044114e-06\n",
      " -2.55450187e-04  2.23286462e-05 -1.29837747e-04 -7.52873048e-06\n",
      "  5.60715390e-04  5.51056598e-04  5.51060888e-04  5.22563533e-04\n",
      "  5.19260092e-04  5.19240992e-04  6.72025651e-05 -3.52717112e-06\n",
      " -2.58600256e-06 -1.38199091e-06  1.20549807e-06 -1.23263308e-06\n",
      " -6.51770029e-07 -1.23262403e-06 -7.87083721e-07 -4.66976039e-07\n",
      "  1.72909596e-07 -1.71412274e-06 -6.27937052e-07 -1.23264732e-06\n",
      "  7.07237049e-07 -1.39936946e-06 -7.45352737e-07 -9.01580876e-07\n",
      " -1.54815577e-06 -7.58040231e-07  5.72258807e-08 -7.46193407e-07\n",
      " -7.84957803e-08 -9.64300099e-08 -1.70487389e-06 -1.74334699e-06\n",
      " -1.74335206e-06 -1.23037298e-06 -1.23264271e-06 -1.23264562e-06\n",
      "  5.76079161e-08  1.66985973e-08 -8.08718395e-09 -7.97626790e-09\n",
      "  1.02254908e-08  2.92610649e-09  4.07603581e-09  2.92609753e-09\n",
      " -2.07677708e-09  6.27664031e-08  5.55790170e-10 -6.19814756e-09\n",
      "  3.59315380e-09  2.92612154e-09  3.95599377e-09  1.86850863e-11\n",
      " -4.09754720e-11 -2.81922809e-09  9.62460287e-11  1.62378109e-11\n",
      "  1.38556709e-08  1.04830802e-10 -2.39764149e-10 -8.71793486e-10\n",
      "  5.39009154e-09  5.51534954e-09  5.51534825e-09  2.91799927e-09\n",
      "  2.92611478e-09  2.92611627e-09 -2.31657433e-09 -8.28470334e-11\n",
      " -2.96233942e-11 -6.38543280e-11  2.26779512e-10 -6.94612758e-12\n",
      "  1.43939185e-12 -6.94610078e-12 -5.97120391e-12  1.27928375e-08\n",
      " -1.45769343e-12 -3.49959400e-11 -3.12999356e-12 -6.94617564e-12\n",
      "  2.05223934e-11 -1.49246566e-11 -5.37789954e-12 -1.36311132e-11\n",
      " -1.56253569e-11 -5.51873914e-12  1.21200218e-09 -5.46237513e-12\n",
      " -3.33751131e-12 -5.48133672e-12 -1.68853333e-11 -1.74486166e-11\n",
      " -1.74486112e-11 -6.92181779e-12 -6.94615425e-12 -6.94615895e-12\n",
      " -4.28540601e-11  4.00996199e-13 -1.71058932e-13 -7.98531684e-13\n",
      "  1.16920531e-11  1.64890413e-14  4.78330732e-14  1.64889617e-14\n",
      " -1.82114520e-14  2.48452746e-09 -5.12736254e-14 -3.36651362e-13\n",
      "  1.76384450e-14  1.64891838e-14  2.80019335e-14  3.61796584e-16\n",
      " -2.34571168e-16 -1.19368225e-13  9.10047246e-16  1.02759915e-16\n",
      "  1.26910309e-10  6.69618451e-16 -3.91062785e-14 -2.92504032e-14\n",
      "  5.30104281e-14  5.52012561e-14  5.52012345e-14  1.64156421e-14\n",
      "  1.64891204e-14  1.64891343e-14 -7.14651973e-13 -1.96746167e-15\n",
      " -2.05697152e-15 -1.50508167e-14  7.43586647e-13 -3.91424543e-17\n",
      "  1.80799816e-16 -3.91422278e-17 -5.79831615e-17  4.82040998e-10\n",
      " -8.28183860e-16 -4.71918282e-15 -1.62891744e-17 -3.91428605e-17\n",
      " -4.37555808e-15 -1.80018907e-16 -4.59701555e-17 -1.65654877e-15\n",
      " -1.74947519e-16 -4.75810357e-17  1.35633915e-11 -4.76649745e-17\n",
      " -4.36380088e-16 -1.43506159e-16 -1.66339482e-16 -1.74637264e-16\n",
      " -1.74637182e-16 -3.89347498e-17 -3.91426796e-17 -3.91427194e-17\n",
      " -1.28586379e-14  9.57135745e-18 -3.81995100e-17 -3.58091970e-16\n",
      "  4.87638433e-14  9.29181815e-20  1.45462558e-18  9.29175541e-20\n",
      " -1.90811586e-19  9.35270771e-11 -1.24098431e-17 -8.03545560e-17\n",
      "  8.89940550e-20  9.29193063e-20 -2.11422867e-16  5.71286551e-21\n",
      " -1.62356004e-21 -2.84560034e-17  9.12949849e-21  4.65956048e-22\n",
      "  1.45174553e-12  5.16305564e-21 -4.98589632e-18 -6.71676459e-19\n",
      "  5.21950546e-19  5.52490582e-19  5.52490280e-19  9.23417391e-20\n",
      "  9.29188056e-20  9.29189157e-20 -2.52839648e-16] 0.45861830696143885\n"
     ]
    }
   ],
   "source": [
    "max_iter = 100\n",
    "lambda_ = 0.7\n",
    "N_w = len(x_train[1,:])\n",
    "initial_w = np.zeros(N_w)\n",
    "w_RR_GD, loss_RR_GD = ridge_regression_GD(y_train, x_train, initial_w, lambda_, max_iter, verbose=False)\n",
    "print(w_RR_GD, loss_RR_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LOSS TEST:')\n",
    "print('GD: ', compute_MSE(y_test,x_test,w_GD))\n",
    "print('GD2: ', compute_MSE(y_test,x_test,w_GD2))\n",
    "print('sGD: ', compute_MSE(y_test,x_test,w_sGD))\n",
    "print('LS: ', compute_MSE(y_test,x_test,w_LS))\n",
    "print('RR: ', compute_MSE(y_test,x_test,w_RR))\n",
    "print('LR_SGD: ', compute_MSE(y_test,x_test,w_LR_SGD))\n",
    "print('LR_GD: ', compute_MSE(y_test,x_test,w_LR_GD))\n",
    "print('RLR_SGD: ', compute_MSE(y_test,x_test,w_RLR_SGD))\n",
    "print('RLR_GD: ', compute_MSE(y_test,x_test,w_RLR_GD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the weight you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w_GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'result/to_try.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, build_poly(tX_test,degree))\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(build_poly(tX_test,degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
